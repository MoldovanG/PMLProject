{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "\n",
    "#stop-words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# tokenizing\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string\n",
    "import preprocessor as p\n",
    "import re\n",
    "import keras.preprocessing.text as kpt\n",
    "from nltk.stem import SnowballStemmer\n",
    "def clean_tweets(tweets):\n",
    "        stemmer = SnowballStemmer(\"german\")\n",
    "        german_stop_words = stopwords.words('german')\n",
    "        new_tweets =[]\n",
    "        for tweet in tweets:\n",
    "            tweet = tweet.lower()\n",
    "            tweet = re.sub('[!?,.:\";]', '', tweet)\n",
    "            tweet = p.tokenize(tweet)\n",
    "            cleaned_tweet =[];\n",
    "            separator = \" \"\n",
    "            for word in kpt.text_to_word_sequence(tweet):\n",
    "                if word not in german_stop_words:\n",
    "                    cleaned_tweet.append(stemmer.stem(word))\n",
    "            new_tweets.append(separator.join(cleaned_tweet))\n",
    "        return np.array(new_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22583,)\n"
     ]
    }
   ],
   "source": [
    "corp = pd.read_csv('training.csv')\n",
    "labels = corp[['x_coord','y_coord']]\n",
    "labels = np.asarray(labels).astype('float32')\n",
    "corp = corp['tweet']\n",
    "corp = np.array(corp)\n",
    "corp = clean_tweets(corp)\n",
    "print(corp.shape)\n",
    "no_docs=len(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for document 1  is :  [4, 14, 11, 23, 2, 41, 13, 20, 20, 15, 7, 36, 43, 8, 38, 23, 2, 41, 13, 20, 25, 48, 44, 3, 9, 44, 40, 12, 44, 30, 17, 23, 40, 30, 27, 42, 20, 43, 4, 29, 46, 41, 47, 20, 44, 31, 26, 43, 47, 40]\n",
      "The encoding for document 2  is :  [37, 44, 18, 43, 16, 44, 16, 25, 30, 20, 30, 39, 8, 18, 4, 30, 34, 4, 2, 10, 33, 25, 38, 41, 3, 22, 39, 14, 15, 7, 44, 30, 22, 28, 27, 22, 40, 49, 11, 42, 28, 43, 31, 38, 27, 36, 39, 4, 38, 24, 22, 6, 42, 29, 33, 30, 30, 34, 15, 29, 7, 13, 43, 37, 31, 49, 38, 34, 2, 34, 46, 20, 36, 29, 34, 2, 40, 35, 29, 28, 15, 32, 34, 32, 29, 21, 7, 34, 42, 33, 30]\n",
      "The encoding for document 3  is :  [43, 14, 22, 5, 33, 27, 40, 11, 34, 48, 3, 31, 47, 42, 43, 42, 43, 26, 49, 9, 43, 44, 42, 42, 27, 43, 44, 42]\n",
      "The encoding for document 4  is :  [42, 28, 21, 41, 46, 35, 4]\n",
      "The encoding for document 5  is :  [40, 15, 15, 14, 30, 1, 21, 9, 25, 36, 2, 44, 15, 38, 20, 4, 34, 43, 23, 12, 1, 43, 16, 4, 31, 46, 8, 4, 14, 45, 27, 13, 30, 30, 12, 35, 9, 12]\n",
      "The encoding for document 6  is :  [15, 40, 16, 11, 32, 7, 33, 13, 11, 43, 25, 42, 47, 13, 19, 48, 30, 3, 13, 20, 7, 21, 16, 1, 41, 8, 30]\n",
      "The encoding for document 7  is :  [14, 24, 38, 36, 33, 16, 39, 29, 13, 43, 46, 14, 24, 5, 2, 3, 19, 7, 32, 47, 7, 22, 33, 38, 34, 2, 30, 30, 7, 1, 8, 21, 22, 30]\n",
      "The encoding for document 8  is :  [5, 12, 43, 12, 7, 43, 38, 13, 8, 33, 37, 40, 38, 8, 30, 30, 47, 5, 14]\n",
      "The encoding for document 9  is :  [26, 12, 2, 38, 45, 13, 2, 30, 30, 10, 20, 30, 12, 44, 1, 42, 14, 43, 5, 37, 34, 49, 27, 3, 4, 38, 17, 10, 1, 49, 49, 38, 1, 18, 17, 43, 43, 49, 38, 38, 42, 43, 31, 33, 1, 49, 21, 16, 43, 43, 30, 16, 44, 32, 2, 2, 43, 5, 39, 38, 2, 33, 20, 30, 30, 30, 34, 5, 42, 18, 48, 2, 6, 14, 46, 16, 44, 30, 7, 7, 10, 22, 35, 13, 7, 21, 30, 30, 38, 2, 41]\n",
      "The encoding for document 10  is :  [1, 20, 43, 44, 33, 42, 37, 7, 43, 31, 19, 39, 24, 34, 34, 17, 43, 3, 16, 38, 8, 44, 4, 35, 23, 44, 44, 35, 43, 7, 43, 45, 19, 26, 12, 2, 5, 1, 28, 22, 22, 43, 31, 13, 43, 6, 44, 1, 22, 49, 5, 38, 28, 44, 16, 13, 41, 44, 17, 43, 13, 30, 44, 13, 23, 4, 11, 39, 37, 49, 44, 33, 3, 44, 46, 1, 37, 17, 45, 49, 12, 31, 20, 35]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=500 \n",
    "encod_corp=[]\n",
    "for i,doc in enumerate(corp):\n",
    "    encod_corp.append(one_hot(doc,vocab_size))\n",
    "    if i < 10 : \n",
    "        print(\"The encoding for document\",i+1,\" is : \",one_hot(doc,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of words in any document is :  163\n"
     ]
    }
   ],
   "source": [
    "maxlen=-1\n",
    "for doc in corp:\n",
    "    tokens=nltk.word_tokenize(doc)\n",
    "    if(maxlen<len(tokens)):\n",
    "        maxlen=len(tokens)\n",
    "maxlen = 163\n",
    "print(\"The maximum number of words in any document is : \",maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of padded documents:  22583\n"
     ]
    }
   ],
   "source": [
    "pad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='post',value=0.0)\n",
    "print(\"No of padded documents: \",len(pad_corp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padded encoding for document 1  is :  [368 388 494 104 461  84 339 170 451 233 462 482 208  17 498 104 461  84\n",
      " 339 170 427 308  63 480 154 495 222 352  66 367  98 376 275 367 316 305\n",
      " 375 208  28 297 108 335  13 451  66  28 494 437  13  23   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 2  is :  [ 47  66 231 208 208  66  74 184 367  60 367 469 361 231 193 367 273 193\n",
      "  88 268  78 143 155  28 480 411 469 241 470 482 495 367   7 366  44  84\n",
      "  17 398 270 447 210  51 272 155 248 111 469 443 155 368 249 300 447 276\n",
      " 204 367 367 273 154 297  23 339 208 231  28 144 135 273 350 273 170 376\n",
      " 111 322 273 399  66 186 297 366 299 446 273 446 297 219  23 273 447  31\n",
      " 367   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 3  is :  [208 388 233 182 457  52  45 264 468 462 104  52 197 447 208 293 424 315\n",
      " 240 161 208 343 293 447  52 208 343 293   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 4  is :  [125  78 372 211 297 318  59   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 5  is :  [424 108 201  15 367  63  48 353  39 456 359 470 323 128 333  35 273 208\n",
      " 376 390 488 324 109  35  28 145 176 408  15 253 159 142 367 367 426 118\n",
      " 186 392   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 6  is :  [470  73  12 301 126 462 498 435 192 208 143 426  13 339 255 115 367  35\n",
      " 339 170  34 170  12  63 285  21 367   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 7  is :  [388 339 423  70 384 230 184 137 254 208 151 388 339  81 324  49 452 462\n",
      " 499  98 462 360  31 468   6 324 367 367 462 254  17 219 238 367   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 8  is :  [279 449  13  88 462 195 155  19 318 370  59 230 336 216 367 367 180 279\n",
      "  95   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 9  is :  [301 379 324 427 304 339 455 367 367  74 375 367  25 204  63  31 388 346\n",
      " 279 122 273 445 316 186  92 334  34 164  63 398 135 228  63 441 271 208\n",
      " 208 445 126 126 447 208 324  78  32 406  90 476 208 346 367 109 419 126\n",
      " 139 461 208  72 448 228 399 384 375 367 367 367 273 121 447 441 203 180\n",
      "  62 317 432 311 379 367 469 462 456 172 400 434 469 211 367 367 440 188\n",
      "  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "The padded encoding for document 10  is :  [ 63 305 167 424 384 166 152 462   2  28 452  88 248 468 360 479 360 104\n",
      "  74  46  77 424 306 361 211 194 246 318 208 462 167  70 314 315 410 300\n",
      "  81 100 431   7  49  74  11 339  80 274 424  63  89  41  81 153  94 424\n",
      "   6 339 157 208 271 167  18  36 424 339 356 327 245 358 251 460 194 457\n",
      " 472 246 224 183 127 390  36 304 129  28 376 318   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(pad_corp):\n",
    "    if i < 10:\n",
    "        print(\"The padded encoding for document\",i+1,\" is : \",doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=Input(shape=(no_docs,maxlen),dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
    "\n",
    "# creating the embedding\n",
    "word_embedding=Embedding(input_dim=vocab_size,output_dim=8,input_length=maxlen)(word_input)\n",
    "\n",
    "word_vec=Flatten()(word_embedding) # flatten\n",
    "embed_model =Model([word_input],word_vec) # combining all into a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),loss='binary_crossentropy',metrics=['acc']) \n",
    "# compiling the model. parameters can be tuned as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=embed_model.predict(pad_corp) # finally getting the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (22583, 1304)\n",
      "[[ 0.0014898   0.02367235 -0.02727101 ...  0.04181394  0.03304669\n",
      "   0.00461565]\n",
      " [ 0.04116328 -0.04411019  0.02400515 ...  0.04181394  0.03304669\n",
      "   0.00461565]\n",
      " [-0.01254798 -0.02896338  0.00571003 ...  0.04181394  0.03304669\n",
      "   0.00461565]\n",
      " ...\n",
      " [ 0.0465141  -0.00689527  0.02573087 ...  0.04181394  0.03304669\n",
      "   0.00461565]\n",
      " [ 0.04504078 -0.00161718 -0.00223484 ...  0.04181394  0.03304669\n",
      "   0.00461565]\n",
      " [-0.00362154  0.03492601  0.01847563 ...  0.04181394  0.03304669\n",
      "   0.00461565]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of embeddings : \",embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3044, 163, 8)\n",
      "[[[ 0.00737191 -0.01072978  0.04837361 ... -0.04897338  0.04107499\n",
      "   -0.02110729]\n",
      "  [ 0.01007394  0.01935105  0.03972271 ...  0.044522   -0.00850205\n",
      "   -0.01058699]\n",
      "  [-0.02017479 -0.00364791  0.0089342  ... -0.03343781  0.01522208\n",
      "   -0.03107841]\n",
      "  ...\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]]\n",
      "\n",
      " [[ 0.02506054  0.01809522 -0.01266562 ... -0.00267894 -0.04480786\n",
      "   -0.02374984]\n",
      "  [-0.03563181 -0.0059803   0.00458474 ...  0.03748833 -0.01929357\n",
      "   -0.02354547]\n",
      "  [ 0.00561469  0.02385304 -0.03038219 ...  0.01152345 -0.04293685\n",
      "    0.04764937]\n",
      "  ...\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]]\n",
      "\n",
      " [[-0.04566423 -0.02285142  0.03306036 ...  0.00743739 -0.04140482\n",
      "   -0.00209618]\n",
      "  [-0.03223264  0.02993159  0.03976906 ...  0.02865405 -0.02720921\n",
      "    0.04537717]\n",
      "  [-0.03226839 -0.001274    0.03274593 ... -0.00451746 -0.01593446\n",
      "   -0.02367555]\n",
      "  ...\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.02254662 -0.01637573  0.00437595 ... -0.04397354 -0.04039457\n",
      "   -0.03553823]\n",
      "  [-0.01133609  0.01509667 -0.02024679 ... -0.04871513 -0.025938\n",
      "    0.02099601]\n",
      "  [ 0.01158254  0.02424871  0.00356871 ...  0.02300284 -0.04186641\n",
      "    0.03481151]\n",
      "  ...\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]]\n",
      "\n",
      " [[ 0.03422823  0.03594743 -0.01906018 ...  0.0043982  -0.00986774\n",
      "    0.0311583 ]\n",
      "  [ 0.02871     0.01878584  0.03067647 ...  0.03301933 -0.01089579\n",
      "    0.01957551]\n",
      "  [-0.01508751  0.04594609 -0.04520991 ...  0.02546603 -0.02560005\n",
      "   -0.04010438]\n",
      "  ...\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]]\n",
      "\n",
      " [[-0.02093896 -0.01184237 -0.02155354 ... -0.00611038  0.02628687\n",
      "    0.00414926]\n",
      "  [ 0.03987798  0.02273092  0.03598962 ...  0.04476608 -0.03705474\n",
      "   -0.00569336]\n",
      "  [-0.02799018  0.03498207 -0.00376617 ... -0.0223376   0.04616303\n",
      "   -0.00819262]\n",
      "  ...\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]\n",
      "  [-0.04654595  0.03871806 -0.00667898 ...  0.04821194  0.04132337\n",
      "   -0.04238854]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings=embeddings.reshape(-1,maxlen,8)\n",
    "print(\"Shape of embeddings : \",embeddings.shape) \n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22583, 1304)\n"
     ]
    }
   ],
   "source": [
    "new_embeddings = []\n",
    "for embed in embeddings:\n",
    "    new_embeddings.append(embed.flatten())\n",
    "new_embeddings = np.array(new_embeddings)\n",
    "print(new_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22583, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LinearRegressionModel = LinearRegression()\n",
    "LinearRegressionModel.fit(new_embeddings,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.653076   9.5217285]\n",
      "1.2488022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = LinearRegressionModel.predict(new_embeddings)\n",
    "print(y_pred[0])\n",
    "print(mean_squared_error(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
