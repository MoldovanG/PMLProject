{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "class DatasetLoader:\n",
    "    def __init__(self):\n",
    "        # Definirea modelelor de prepocesare a tweet-urilor\n",
    "        self.count_vectorizer = CountVectorizer(encoding='utf-8',lowercase=True, stop_words=stopwords.words('german'),ngram_range=(1, 1),max_df=0.5, min_df=0, binary = True, max_features = 20000)\n",
    "        self.tfidf_transformer  = TfidfTransformer( norm='l2',use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "    def load_train_data(self,csv_file_path):\n",
    "        data_frame = pd.read_csv(csv_file_path)\n",
    "        data = np.array(data_frame)\n",
    "        self.train_ids = data[:,0]\n",
    "        self.train_labels = np.asarray(data[:,1:3]).astype('float32')\n",
    "        self.train_processed_tweets = self.count_vectorizer.fit_transform(data[:,3])\n",
    "        self.train_processed_tweets = self.tfidf_transformer.fit_transform(self.train_processed_tweets)\n",
    "    def load_test_data(self,csv_file_path):\n",
    "        data_frame = pd.read_csv(csv_file_path)\n",
    "        data = np.array(data_frame)\n",
    "        self.test_ids = data[:,0]\n",
    "        self.test_processed_tweets = self.tfidf_transformer.transform(self.count_vectorizer.transform(data[:,1]))\n",
    "        \n",
    "    def load_validation_data(self, csv_file_path):\n",
    "        data_frame = pd.read_csv(csv_file_path)\n",
    "        data = np.array(data_frame)\n",
    "        self.validation_ids = data[:,0]\n",
    "        self.validation_labels = np.asarray(data[:,1:3]).astype('float32')\n",
    "        self.validation_processed_tweets = self.tfidf_transformer.transform(self.count_vectorizer.transform(data[:,3]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22583, 20000)\n",
      "(22583, 2)\n",
      "(3044, 20000)\n",
      "(3044, 2)\n"
     ]
    }
   ],
   "source": [
    "# Incarcarea datelor de antrenare,validare si de test.\n",
    "loader = DatasetLoader();\n",
    "loader.load_train_data('training.csv')\n",
    "print(loader.train_processed_tweets.shape)\n",
    "print(loader.train_labels.shape)\n",
    "\n",
    "loader.load_validation_data('validation.csv')\n",
    "print(loader.validation_processed_tweets.shape)\n",
    "print(loader.validation_labels.shape)\n",
    "loader.load_test_data('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import csv \n",
    "class DataSetEvaluator:\n",
    "    def calculateMSE(self, model, labels, processed_features):\n",
    "        y_pred = model.predict(processed_features)\n",
    "        print(y_pred[0])\n",
    "        return mean_squared_error(labels, y_pred)\n",
    "    def calculateMAE(self, model, labels, processed_features):\n",
    "        y_pred = model.predict(processed_features)\n",
    "        print(y_pred[0])\n",
    "        return mean_absolute_error(labels, y_pred)\n",
    "    def generateEvaluationFile(self,model,ids, processed_features, filename):\n",
    "        y_pred = model.predict(processed_features)\n",
    "        print(y_pred[0])\n",
    "        file=open(filename,\"w\")\n",
    "        writes=csv.writer(file,delimiter=',',quoting=csv.QUOTE_ALL)\n",
    "        count =0\n",
    "        for row in y_pred:\n",
    "            writes.writerow([ids[int(count)],row[0],row[1]])\n",
    "            count = count + 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RegressorChain(base_estimator=LinearSVR(C=0.5,\n",
       "                                        loss='squared_epsilon_insensitive',\n",
       "                                        random_state=1242))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "#Definirea modelului de baza\n",
    "LinearSvrModel = LinearSVR(C=0.5,random_state=1242,loss='squared_epsilon_insensitive')\n",
    "#Creeaza o inlanturie de modele pentru a genera un output bidimensional.\n",
    "LinearSvrWrapper = RegressorChain(LinearSvrModel)\n",
    "LinearSvrWrapper.fit(loader.train_processed_tweets,loader.train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.94081123  9.76800256]\n",
      "MSE : 0.5930440608413687\n",
      "[51.94081123  9.76800256]\n",
      "MAE : 0.5863074767024781\n",
      "[51.79599767 10.53477428]\n"
     ]
    }
   ],
   "source": [
    "evaluator = DataSetEvaluator()\n",
    "print('MSE : ' + str(evaluator.calculateMSE(LinearSvrWrapper, loader.validation_labels, loader.validation_processed_tweets)))\n",
    "print('MAE : ' + str(evaluator.calculateMAE(LinearSvrWrapper, loader.validation_labels, loader.validation_processed_tweets)))\n",
    "evaluator.generateEvaluationFile(LinearSvrWrapper, loader.test_ids, loader.test_processed_tweets, 'linearSvrSubmission3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(LinearSvrWrapper, open('best_svr_wrapper_model.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
